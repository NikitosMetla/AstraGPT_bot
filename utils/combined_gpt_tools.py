from __future__ import annotations

import asyncio
import base64
import io
import json
import os
import pprint
import traceback
from collections import defaultdict
from typing import Any, Awaitable, Callable, Optional, Sequence, Literal
from typing import Dict

import aiohttp
from dotenv import find_dotenv, load_dotenv
from openai import (
    APIConnectionError,
    APIStatusError,
    APITimeoutError,
    AsyncOpenAI,
    AuthenticationError,
    PermissionDeniedError,
    RateLimitError, BadRequestError, )

from data.keyboards import subscriptions_keyboard
from settings import get_current_datetime_string, print_log
from utils import web_search_agent
from utils.create_notification import schedule_notification, NotificationSchedulerError
from utils.parse_gpt_text import sanitize_with_links
from utils.runway_api import generate_image_bytes

# combined_gpt_tools.py

_thread_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)


class NoSubscription(Exception):
    """–û—à–∏–±–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏"""
    pass


import asyncio
from openai import InternalServerError

async def retrieve_with_retry(client, file_id: str, max_attempts: int = 4, base_delay: float = 0.5):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –∏–∑ OpenAI API —Å –ø–æ–º–æ—â—å—é client.files.retrieve,
    –ø–æ–≤—Ç–æ—Ä—è—è –¥–æ max_attempts —Ä–∞–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ InternalServerError (–∫–æ–¥ 502).
    """
    attempt = 0
    while attempt < max_attempts:
        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            file_info = await client.files.retrieve(file_id=file_id, timeout=3)
            return file_info
        except InternalServerError:
            print(traceback.format_exc())
            # –ü–æ–≤—Ç–æ—Ä –≤–æ–∑–Ω–∏–∫ –∏–∑-–∑–∞ 502 Bad Gateway
            attempt += 1
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É: base_delay * 2^(attempt-1)
            delay = base_delay * (2 ** (attempt - 1))
            # –ñ–¥—ë–º delay —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
            await asyncio.sleep(delay)
    # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–∞–ª—å—à–µ –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª {file_id} –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫")



async def get_thread_lock(thread_id: str) -> asyncio.Lock:
    # defaultdict –≤–µ—Ä–Ω—ë—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–ª–∏ —Å–æ–∑–¥–∞—Å—Ç –Ω–æ–≤—ã–π Lock
    return _thread_locks[thread_id]


load_dotenv(find_dotenv())
OPENAI_API_KEY: str | None = os.getenv("GPT_TOKEN") or os.getenv("OPENAI_API_KEY")
assistant_id = os.getenv("ASSISTANT_ID")
DEFAULT_IMAGE_MODEL = "gpt-image-1"
DEFAULT_IMAGE_SIZE = "1024x1024"

# --- –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è ---
def _strip_response_format(kwargs: dict) -> dict:
    # –≤—ã—á–∏—â–∞–µ–º response_format, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å gpt-image-1
    if (kwargs.get("model") or DEFAULT_IMAGE_MODEL).startswith("gpt-image-1"):
        kwargs.pop("response_format", None)
    return kwargs


UNSUPPORTED_FOR_GPT_IMAGE = {"response_format", "style"}

def _strip_unsupported_params(kwargs: dict) -> dict:
    if (kwargs.get("model") or DEFAULT_IMAGE_MODEL).startswith("gpt-image-1"):
        for p in UNSUPPORTED_FOR_GPT_IMAGE:
            kwargs.pop(p, None)
    return kwargs


def _b64(b: bytes) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Base64‚Äë—Å—Ç—Ä–æ–∫—É –∏–∑ –±–∞–π—Ç–æ–≤."""
    return base64.b64encode(b).decode()

def _b64decode(s: str) -> bytes:
    """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç Base64‚Äë—Å—Ç—Ä–æ–∫—É –≤¬†–±–∞–π—Ç—ã."""
    return base64.b64decode(s)

async def _retry(
    fn: Callable[..., Awaitable[Any]],
    *args,
    attempts: int = 6,
    backoff: float = 1.5,
    **kwargs,
):
    """–ü–æ–≤—Ç–æ—Ä—è–µ—Ç –≤—ã–∑–æ–≤ *fn* —Å¬†—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö."""
    for attempt in range(1, attempts + 1):
        try:
            return await fn(*args, **kwargs)
        except (APITimeoutError, APIConnectionError, APIStatusError, RateLimitError):
            if attempt == attempts:
                raise
            await asyncio.sleep(backoff ** attempt)
        except (AuthenticationError, PermissionDeniedError):
            raise  # –æ—à–∏–±–∫–∏ –Ω–µ—É—Å—Ç—Ä–∞–Ω–∏–º—ã

class AsyncOpenAIImageClient:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ Image‚Äë—ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º–∏ OpenAI."""

    def __init__(
        self,
        *,
        api_key: str | None = OPENAI_API_KEY,
        organization: str | None = None,
        default_model: str = DEFAULT_IMAGE_MODEL,
        vision_model: str = "gpt-4o-mini",
    ) -> None:
        """–°–æ–∑–¥–∞—ë—Ç –∫–ª–∏–µ–Ω—Ç–∞ —Å¬†–±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏¬†vision."""
        self.client = AsyncOpenAI(api_key=api_key, organization=organization)
        self.default_model = default_model
        self.vision_model = vision_model  # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤¬†ImageChatSession

    # ---------- 1. GENERATE ----------
    async def generate(
            self,
            prompt: str,
            *,
            n: int = 1,
            size: str = DEFAULT_IMAGE_SIZE,
            quality: Literal["high", "medium", "low"] = "medium",
            user: str | None = None,
            model: str | None = None,
            images: Any | None = None,
    ) -> list[bytes]:
        model = model or self.default_model
        if images is None:
            params: dict[str, Any] = {
                "model": model,
                "prompt": prompt,
                "n": n,
                "size": size,
                "quality": quality,
                "response_format": "b64_json",
                "user": user,
                "timeout": 120
            }
            params = _strip_unsupported_params(params)
            rsp = await _retry(self.client.images.generate, **params)
            return [_b64decode(item.b64_json) for item in rsp.data]
        params: dict[str, Any] = {
            "model": model,
            "prompt": prompt,
            "image": images[0],
            "timeout": 120
        }
        rsp = await _retry(self.client.images.edit, **params)
        return [_b64decode(item.b64_json) for item in rsp.data]





def _image_content(b: bytes, detail: str = "auto") -> dict:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–ª–æ–≤–∞—Ä—å‚Äë–∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    return {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{_b64(b)}"}, "detail": detail}



from os import getenv as _getenv
from db.models import Users
from db.repository import users_repository, subscriptions_repository, type_subscriptions_repository

api_key = OPENAI_API_KEY


class GPT:  # noqa: N801 ‚Äì —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, —Ä–∞–±–æ—Ç–∞—é—â–∏–π —á–µ—Ä–µ–∑ Threads/Assistants API."""

    def __init__(self, assistant_id: str | None = assistant_id):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç GPT-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º *thread_id*."""
        self.assistant_id = assistant_id
        self.client = AsyncOpenAI(api_key=api_key)
        self.assistant = None
        # thread_id –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –≤ –º–µ—Ç–æ–¥–µ send_message –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        self.vector_store_id: str | None = None

    async def _safe_create_run(self, *, thread_id: str, assistant_id: str,
                               instructions: str, model: str,
                               timeout: float, max_retry: int = 3):
        for attempt in range(max_retry):
            try:
                return await self.client.beta.threads.runs.create_and_poll(
                    thread_id=thread_id,
                    assistant_id=assistant_id,
                    instructions=instructions,
                    model=model,
                    timeout=timeout,
                )
            except BadRequestError as e:
                # –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π run ‚Äî –¥–æ–∂–¥–∞—Ç—å—Å—è –µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
                if "already has an active run" in str(e) and attempt < max_retry - 1:
                    await self._wait_for_active_run(thread_id)
                    continue
                # –≤–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—å –æ—à–∏–±–∫—É –¥–∞–ª—å—à–µ
                raise

    async def _ensure_assistant(self):
        """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–∫—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
        if self.assistant is None:
            self.assistant = await self.client.beta.assistants.retrieve(assistant_id=self.assistant_id)

    async def _ensure_thread(self, *, user_id: int, thread_id: str | None = None):
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ thread: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –∏–ª–∏ —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π."""
        if thread_id is None:
            thread = await self._create_thread(user_id)
        else:
            thread = await self.client.beta.threads.retrieve(thread_id=thread_id)
        return thread

    async def _create_thread(self, user_id: int, type_assistant: str | None = "mental"):
        """–°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π thread –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –≤ –ë–î; –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã–π thread."""
        thread = await self.client.beta.threads.create()
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç—Ä–µ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await users_repository.update_thread_id_by_user_id(user_id=user_id, thread_id=thread.id)
        return thread

    async def _sync_vector_store(self, thread_id: str, file_ids: list[str]) -> str:
        """
        –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç –∫ thread –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π vector‚Äëstore,
        —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–æ—á–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä file_ids.
        """
        thread = await self.client.beta.threads.retrieve(thread_id)

        # 1. –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π vs, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –µ—Å—Ç—å
        vs_ids = []
        if thread.tool_resources and thread.tool_resources.file_search:
            vs_ids = thread.tool_resources.file_search.vector_store_ids or []

        vs_id = vs_ids[0] if vs_ids else None

        # 2. —Å–æ–∑–¥–∞—ë–º VS –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏
        if vs_id is None:
            vs = await self.client.vector_stores.create(
                name=f"vs-{thread_id}",
                file_ids=file_ids,
            )
            vs_id = vs.id

            await self.client.beta.threads.update(
                thread_id=thread_id,
                tool_resources={"file_search": {"vector_store_ids": [vs_id]}},
            )
        else:
            # 3. —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            current_ids = {
                f.id
                for f in (await self.client.vector_stores.files.list(vs_id)).data
            }

            # —É–¥–∞–ª–∏—Ç—å –ª–∏—à–Ω–∏–µ
            for fid in current_ids - set(file_ids):
                await self.client.vector_stores.files.delete(vector_store_id=vs_id, file_id=fid)

            # –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ
            for fid in set(file_ids) - current_ids:
                await self.client.vector_stores.files.create(
                    vector_store_id=vs_id,
                    file_id=fid,
                )

        # 4. –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        while (await self.client.vector_stores.retrieve(vs_id)).status != "completed":
            await asyncio.sleep(0.3)

        return vs_id

    async def send_message(
        self,
        user_id: int,
        thread_id: str | None = None,
        *,
        with_audio_transcription: bool = False,
        text: str | None = None,
        image_bytes: Sequence[io.BytesIO] | None = None,
        document_bytes: Sequence[tuple[io.BytesIO, str, str]] | None = None,
        document_type: str | None = None,
        audio_bytes: io.BytesIO | None = None,
        user_data: Users | None = None,
    ):
        from bot import logger
        from settings import get_weekday_russian
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –≤–ª–æ–∂–µ–Ω–∏—è–º–∏."""
        # –ü—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—Ä–æ—Å–µ –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π thread, –µ—Å–ª–∏ –æ–Ω –ø–µ—Ä–µ–¥–∞–Ω —è–≤–Ω–æ
        await self._ensure_assistant()
        if thread_id is None:
            thread = await self._ensure_thread(user_id=user_id, thread_id=thread_id)
            thread_id = thread.id
        lock = await get_thread_lock(thread_id)
        async with lock:  # ‚¨ÖÔ∏è  –í–°–ï –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å thread ‚Äì –ø–æ–¥ –∑–∞–º–∫–æ–º
            await self._wait_for_active_run(thread_id)

            # about_user = self._build_about_user(user_data)
            user = await users_repository.get_user_by_user_id(user_id=user_id)
            about_user = user.context
            text = (text or "–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
            # print(document_bytes)
            if not any([text, image_bytes, document_bytes, audio_bytes]):
                return None
            # print(text)
            content, attachments, file_ids = await self._build_content(
                text,
                image_bytes=image_bytes,
                document_bytes=document_bytes,
                audio_bytes=audio_bytes,
            )
            # print(content)
            if file_ids:
                await self._sync_vector_store(thread_id, file_ids)
            # print(attachments)
            try:
                await self.client.beta.threads.messages.create(
                    thread_id=thread_id,
                    role="user",
                    content=content,
                    attachments=attachments or None,
                    timeout=15.0,
                )
                # 4. –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π run –∏ –∂–¥—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                run = await self._safe_create_run(
                    thread_id=thread_id,
                    assistant_id=self.assistant.id,
                    instructions=f"–°–µ–≥–æ–¥–Ω—è - {get_current_datetime_string()}\n\n –ø–æ –ú–æ—Å–∫–≤–µ.–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ - {get_weekday_russian()} "
                                 f"–£—á–∏—Ç—ã–≤–∞–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é,"
                                 f" –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ—Å—Ç–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ\n\n–û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n" + self.assistant.instructions +
                                 f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n{about_user}" if about_user else f"–°–µ–≥–æ–¥–Ω—è - {get_current_datetime_string()}\n\n"
                                                                                                    f" –ø–æ –ú–æ—Å–∫–≤–µ.–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ - {get_weekday_russian()}" +
                                                               self.assistant.instructions,
                    model=user.model_type,
                    timeout=15.0,
                )
                # print("–°–µ–≥–æ–¥–Ω—è - ", get_current_datetime_string())
                # ---------------- NEW: –æ–±—Ä–∞–±–æ—Ç–∫–∞ image‚Äëtools ----------------
                if run.status == "requires_action":
                    from bot import main_bot
                    user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user.user_id)
                    sub_types = await type_subscriptions_repository.select_all_type_subscriptions()
                    if user_sub is None:
                        from test_bot import test_bot
                        from settings import sub_text
                        await test_bot.send_message(chat_id=user.user_id,
                                                    text="üö®–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –¥–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä—É—é —Ç—ã"
                                                " –ø—ã—Ç–∞–µ—à—å—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –ø–æ –ø–æ–¥–ø–∏—Å–∫–µ\n\n" + sub_text,
                                                    reply_markup=subscriptions_keyboard(sub_types).as_markup())
                        raise NoSubscription(f"User {user.user_id} dont has active subscription")
                    delete_message = None
                    for tc in run.required_action.submit_tool_outputs.tool_calls:
                        if tc.function.name == "search_web":
                            delete_message = await main_bot.send_message(text="üîç–ù–∞—á–∞–ª –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—ã...",
                                                                         chat_id=user.user_id)
                        elif tc.function.name == "add_notification":
                            delete_message = await main_bot.send_message(
                                text="üñå–ù–∞—á–∞–ª –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ, —ç—Ç–æ –Ω–µ –∑–∞–π–º–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏...",
                                chat_id=user.user_id)
                        else:
                            if user_sub.photo_generations <= 0:
                                return "–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, —É —Ç–µ–±—è –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–≤–æ–µ–º—É –ø–ª–∞–Ω—É"
                            delete_message = await main_bot.send_message(chat_id=user.user_id,
                                                                         text="üé®–ù–∞—á–∞–ª —Ä–∞–±–æ—Ç—É –Ω–∞–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º, –Ω–µ–º–Ω–æ–≥–æ –º–∞–≥–∏–∏‚Ä¶")
                        break
                    try:
                        result = await process_assistant_run(self.client, run, thread_id, user_id=user.user_id)
                        result_images = result.get("final_images")
                        web_answer: str = result.get("web_answer")
                        notification: str = result.get("notif_answer")
                        if len(result_images) == 0 and web_answer is None and notification is None:
                            try:
                                await delete_message.delete()
                            finally:
                                # from bot import logger
                                # logger.error("–ù–µ —Å–º–æ–≥–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Åüòî\n\n–í–æ–∑–º–æ–∂–Ω–æ,"
                                #         " —Ç—ã –ø–æ–ø—Ä–æ—Å–∏–ª —á—Ç–æ-—Ç–æ, —á—Ç–æ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ –Ω–æ—Ä–º", result)
                                return ("–ù–µ —Å–º–æ–≥–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Åüòî\n\n–í–æ–∑–º–æ–∂–Ω–æ,"
                                        " —Ç—ã –ø–æ–ø—Ä–æ—Å–∏–ª —á—Ç–æ-—Ç–æ, —á—Ç–æ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ –Ω–æ—Ä–º")
                        messages = await self.client.beta.threads.messages.list(thread_id=thread_id)
                        await delete_message.delete()
                        first_msg = messages.data[0]
                        if web_answer:
                            return sanitize_with_links(web_answer)
                        if notification:
                            return sanitize_with_links(notification)
                        elif len(result_images) != 0:
                            return {"text": first_msg.content[0].text.value if hasattr(first_msg.content[0], "text") else "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                                    "images": result_images}
                    except Exception:
                        print(traceback.format_exc())
                        await delete_message.delete()
                        from bot import logger
                        logger.log(
                            "GPT_ERROR",
                            f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}"
                        )
                        print_log(message=f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}")
                        return ("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑!"
                                " –¢–≤–æ–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π"
                                " –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                if run.status == "completed":
                    messages = await self.client.beta.threads.messages.list(thread_id=thread_id)
                    if messages.data[0].content[0].type == "image_file":
                        # print(messages.data[0].content[0].image_file)
                        image_file = messages.data[0].content[0].image_file
                        file_id = image_file.file_id
                        file_obj = await self.client.files.retrieve(file_id=file_id)
                        # pprint.pprint(file_obj.json)
                        data = await self.client.files.content(file_id)
                        return {"filename": file_obj.filename + ".png", "bytes": await data.aread()}
                    # message_text = _sanitize(
                    #     messages.data[0].content[0].text.value
                    # )
                    # pprint.pprint(messages.data[0].attachments)
                    if messages.data[0].attachments:
                        # print(messages.data[0].content[0].text.value)
                        for content in messages.data[0].attachments:
                            # print(content)
                            file_id = content.file_id
                            file_obj = await self.client.files.retrieve(file_id=file_id)
                            data = await self.client.files.content(file_id)
                            return {"filename": file_obj.filename, "bytes": await data.aread()}
                    # files = messages.data[0].file_ids
                    # message_text = re.sub(r"„Äê[^„Äë]+„Äë", "", message_text).strip()
                    message_text = messages.data[0].content[0].text.value
                    if with_audio_transcription:
                        audio_data = await self.generate_audio_by_text(message_text)
                        return sanitize_with_links(message_text), audio_data
                    return sanitize_with_links(message_text)
                # print(run.json)
                logger.log(
                    "GPT_ERROR",
                    f"–ó–ê–ö–û–ù–ß–ò–õ–ò–°–¨ –ë–ê–ë–ö–ò –∏–ª–∏ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ gpt: {run.json()}"
                )
                return ("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑! C–µ–π—á–∞—Å –Ω–∞–±–ª—é–¥–∞—é—Ç—Å—è —Å–±–æ–∏ –≤ —Å–∏—Å—Ç–µ–º–µ")
            except NoSubscription:  # 1. –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∞—Ä–∏—Ñ–Ω—ã–µ –æ—à–∏–±–∫–∏
                raise
            except Exception:
                traceback.print_exc()
                try:
                    await self.client.beta.threads.runs.cancel(run_id=run.id, thread_id=thread_id)
                finally:
                    # –ü—Ä–∏ —Ñ–∞—Ç–∞–ª—å–Ω–æ–π –æ—à–∏–±–∫–µ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç–∞, —á—Ç–æ–±—ã –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                    await self._reset_client()
                    logger.log(
                        "GPT_ERROR",
                        f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}"
                    )
                    print_log(message=f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}")
                    return ("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑! –¢–≤–æ–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å"
                            " –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")

    # -------- –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã --------
    @staticmethod
    async def generate_audio_by_text(text: str) -> io.BytesIO:
        """TTS‚Äë—Å–∏–Ω—Ç–µ–∑ –æ—Ç–≤–µ—Ç–∞ –≤¬†mp3 —á–µ—Ä–µ–∑ /audio/speech."""
        url = "https://api.openai.com/v1/audio/speech"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": "gpt-4o-mini-tts",
            "input": text,
            "voice": "shimmer",
            "instructions": "Speak dramatic",
            "response_format": "mp3",
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, json=payload, timeout=30) as response:
                if response.status == 200:
                    return io.BytesIO(await response.read())
                raise RuntimeError(f"TTS error {response.status}: {await response.text()}")

    @staticmethod
    async def transcribe_audio(audio_bytes: io.BytesIO, language: str = "ru") -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper."""
        url = "https://api.openai.com/v1/audio/transcriptions"
        headers = {"Authorization": f"Bearer {api_key}"}

        audio_bytes.name = "audio.mp3"
        data = {"file": audio_bytes, "model": "whisper-1", "language": language}

        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, data=data, timeout=60) as response:
                if response.status == 200:
                    result = await response.json()
                    return result.get("text", "")
                raise RuntimeError(f"Transcription error {response.status}: {await response.text()}")

    @staticmethod
    def _build_about_user(user: Users | None) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å —Å¬†–¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."""
        if user is None:
            return ""
        parts: list[str] = []
        if user.name not in (None, "NoName"):
            parts.append(f"–ò–º—è: {user.name}")
        if user.gender:
            parts.append(f"–ü–æ–ª: {user.gender}")
        if user.age:
            parts.append(f"–î–∏–∞–ø–∞–∑–æ–Ω –≤–æ–∑—Ä–∞—Å—Ç–∞: {user.age}")

        if not parts:
            return ""

        info = "\n".join(parts)
        prefix = (
            "–û—Ç–≤–µ—á–∞–π —Å —É—á–µ—Ç–æ–º —Å–ª–µ–¥—É—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∏—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏—è "
            "–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –Ω–∞–ø—Ä–∏–º–µ—Ä,  –∏–Ω–æ–≥–¥–∞ –ø–æ –∏–º–µ–Ω–∏, –∏–Ω–æ–≥–¥–∞ –ø—Ä–æ—Å—Ç–æ –ø–æ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—é). –ï—Å–ª–∏ —Ç—ã –≤–∏–¥–∏—à—å, —á—Ç–æ –≤ "
            "–ø—Ä–µ–¥—ã–¥—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ —Ç—ã –æ–±—Ä–∞—â–∞–ª—Å—è –ø–æ –∏–º–µ–Ω–∏, —Ç–æ —Å–µ–π—á–∞—Å –ø–æ –∏–º–µ–Ω–∏ –Ω–µ –æ–±—Ä–∞—â–∞–π—Å—è, –∞ —Ç–∞–∫–∂–µ –Ω–µ –Ω–∞–¥–æ –∫–∞–∂–¥—ã–π "
            "—Ä–∞–∑ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å.\n\n"
        )
        return prefix + info + "\n\n"

    async def _build_content(
            self,
            text: str,
            *,
            image_bytes: Sequence[io.BytesIO] | None,
            document_bytes: Sequence[tuple[io.BytesIO, str, str]] | None,
            audio_bytes: io.BytesIO | None,
    ) -> tuple[list[dict], list[dict], list[str]]:
        content: list[dict] = []
        attachments: list[dict] = []
        doc_file_ids: list[str] = []

        # 1. —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∞—É–¥–∏–æ (–Ω–µ —Ç—Ä–æ–≥–∞–µ–º...)
        # 2. —Ç–µ–∫—Å—Ç
        image_names = []
        # 3. –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if image_bytes:
            for idx, img_io in enumerate(image_bytes):
                img_io.seek(0)
                img_file = await self.client.files.create(
                    file=(f"image_{idx}.png", img_io, "image/png"),
                    purpose="vision",
                )
                while True:
                    if img_file.status in ("uploaded", "processed", "error"):
                        break
                    await asyncio.sleep(0.3)
                while True:
                    try:
                        # print("–ø–æ–ø—ã—Ç–∫–∞")
                        file_info = await retrieve_with_retry(self.client, file_id=img_file.id)
                    except RuntimeError:
                        from bot import logger
                        logger.log(
                            "GPT_ERROR",
                            f" –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}"
                        )
                        print_log(message=f" –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}")
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª –ø–æ—Å–ª–µ retry, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        return [{"type": "text", "text": text}], [], []
                    # –°—Ç–∞—Ç—É—Å –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –≤ —Ä–∞–∑–Ω—ã—Ö SDK, –∑–¥–µ—Å—å –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–µ—á–Ω—ã–π
                    # print(file_info.status)
                    if getattr(file_info, "status", None) in ("uploaded", "processing_complete", "ready", "processed"):
                        break
                    await asyncio.sleep(0.2)
                # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É
                await asyncio.sleep(1)  # –¥–∞—ë–º Vision-–¥–≤–∏–∂–∫—É –Ω–µ–º–Ω–æ–≥–æ ¬´–≤–∑–¥–æ—Ö–Ω—É—Ç—å¬ª

                image_names.append(f"image_{idx}.png")
                content.append({
                    "type": "image_file",
                    "image_file": {"file_id": img_file.id},
                })
                # print(image_names)

            text += f"\n\n–í–æ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {', '.join(image_names)}"

        # 4. –¥–æ–∫—É–º–µ–Ω—Ç—ã
        if document_bytes:
            text += "\n\n–í–æ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —è –ø—Ä–∏–∫—Ä–µ–ø–∏–ª:\n"
            for idx, (doc_io, file_name, mime_ext) in enumerate(document_bytes):
                doc_io.seek(0)
                doc_file = await self.client.files.create(
                    file=(f"{file_name}", doc_io, f"application/{mime_ext}"),
                    purpose="assistants",
                )
                text += f"{file_name} "
                doc_file_ids.append(doc_file.id)
                attachments.append({
                    "file_id": doc_file.id,
                    "tools": [{"type": "file_search"}],
                })
        #
        content.append({"type": "text", "text": f"–°–µ–≥–æ–¥–Ω—è - {get_current_datetime_string()}\n\n –ø–æ –ú–æ—Å–∫–≤–µ.\n\n" + text})
        return content, attachments, doc_file_ids

    async def _wait_for_active_run(
        self,
        thread_id: str,
        poll_interval: float = 0.5,
    ) -> None:
        """
        –ë–ª–æ–∫–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –ø–æ–∫–∞ –≤ thread –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π run.
        –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—á–µ—Ä–µ–¥—å).
        """
        ACTIVE = {"queued", "in_progress", "requires_action", "cancelling", "active"}
        retries = 360
        while retries > 0:
            runs = await self.client.beta.threads.runs.list(
                thread_id=thread_id,
                limit=100,
                order="desc",  # –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–≤—ã–º
            )
            if any(r.status in ACTIVE for r in runs.data):
                await asyncio.sleep(poll_interval)
                retries -= 1
                continue
            break
        else:
            runs = await self.client.beta.threads.runs.list(
                thread_id=thread_id,
                limit=100,
                order="desc",  # –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–≤—ã–º
            )
            for run in runs.data:
                if any(r.status in ACTIVE for r in runs.data):
                    await self.client.beta.threads.runs.cancel(run_id=run.id, timeout=10)

    async def _reset_client(self):
        """–ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞ OpenAI –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∫–µ—à –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
        self.client = AsyncOpenAI(api_key=api_key)
        self.assistant = None


async def dispatch_tool_call(tool_call, image_client, user_id: int) -> Any:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–∞–∫ Pydantic‚Äë–æ–±—ä–µ–∫—Ç RequiredActionFunctionToolCall,
    —Ç–∞–∫ –∏ —Å—Ç–∞—Ä—ã–π —Å–ª–æ–≤–∞—Ä—å (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏).
    """
    # --- 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã ---
    if hasattr(tool_call, "function"):                         # –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
        name = tool_call.function.name
        args_raw = tool_call.function.arguments
    else:                                                      # —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç (dict)
        name = tool_call.get("name") or tool_call.get("function", {}).get("name")
        args_raw = tool_call.get("arguments") or tool_call.get("function", {}).get("arguments")

    # --- 2. –ü—Ä–∏–≤–æ–¥–∏–º arguments –∫¬†dict ---
    import json
    if isinstance(args_raw, dict):
        args = args_raw
    else:
        try:
            args = json.loads(args_raw)
        except json.JSONDecodeError:
            print("\n\n")
            # print(args_raw)
            print("\n\n")
            # –Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–±—Ä–µ–∑–∞—Ç—å –¥–æ –ø–µ—Ä–≤–æ–≥–æ `}` –∏ –¥–æ–øarse
            first_obj = args_raw.split('}', 1)[0] + '}'
            args = json.loads(first_obj)
    from bot import main_bot
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    photo_bytes = []
    if name == "add_notification":
        # print("\n\nadd_notification\n\n")
        when_send_str, text_notification = args.get("when_send_str"), args.get("text_notification")
        # print(args)
        # print("–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏:", when_send_str)
        try:
            await schedule_notification(user_id=user.user_id,
                                        when_send_str=when_send_str,
                                        text_notification=text_notification)
            return f"–û—Ç–ª–∏—á–Ω–æ, –¥–æ–±–∞–≤–∏–ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–∞ {when_send_str} –ø–æ –º–æ—Å–∫–æ–≤—Å–∫–æ–º—É –≤—Ä–µ–º–µ–Ω–∏\n\n–¢–µ–∫—Å—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {text_notification}"
        except NotificationSchedulerError:
            print(traceback.format_exc())
            return "–ù–µ–ª—å–∑—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—à–ª–æ–µ –≤—Ä–µ–º—è –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏"
    if name == "search_web":
        # print("\n\nsearch_web\n\n")
        query = args.get("query") or ""
        # –≤—ã–∑—ã–≤–∞–µ–º –∞–≥–µ–Ω—Ç –∏–∑ web_search_agent.py
        result = await web_search_agent.search_prompt(query)
        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–¥–µ–ª–∏ –∫–∞–∫ plain text
        return result
    if user.last_image_id is not None:
        for photo_id in user.last_image_id.split(", "):
            # print(photo_id)
            photo_bytes_io = io.BytesIO()
            await main_bot.download(photo_id, destination=photo_bytes_io)
            photo_bytes_io.seek(0)
            photo_bytes.append(photo_bytes_io.read())
    # --- 3. –î–∏—Å–ø–∞—Ç—á–∏–Ω–≥ ---
    if name == "generate_image":
        # print("generate_image")
        # print(args.get("edit_existing_photo"))
        try:
            kwargs: dict[str, Any] = {
                "prompt": args["prompt"],
                "n": args.get("n", 1),
                "size": args.get("size", DEFAULT_IMAGE_SIZE),
                "quality": args.get("quality", "low"),
            }
            # print("\n\n\n–ò–∑–º–µ–Ω—è—Ç—å?", args.get("edit_existing_photo"))
            if args.get("edit_existing_photo"):
                kwargs["images"] = [("image.png", io.BytesIO(photo), "image/png") for photo in photo_bytes]
            return await image_client.generate(**kwargs)
        except:
            return []

    if name == "edit_image_only_with_peoples":
        # print("edit_image_only_with_peoples")
        # print(args.get("prompt"))
        # print(args)
        try:
            prompt = args.get("prompt", "").strip()
            prompt = prompt[:400]  # –º–∞–∫—Å–∏–º—É–º 200 —Å–∏–º–≤–æ–ª–æ–≤
            # –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî —É–¥–∞–ª–∏—Ç—å –Ω–µ-ASCII —Å–∏–º–≤–æ–ª—ã
            prompt = prompt.encode('ascii', 'ignore').decode()
            if not prompt:
                # –ª–∏–±–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ–Ω—è—Ç–Ω—É—é –æ—à–∏–±–∫—É, –ª–∏–±–æ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —ç—Ç–æ—Ç tool-call
                return []
            return [await generate_image_bytes(prompt=args.get("prompt"), ratio=args.get("ratio"),
                                               images=photo_bytes if len(photo_bytes) <= 3 else photo_bytes[:3])]
        except RuntimeError as e:
            print(f"Runway task failed for prompt ¬´{prompt}¬ª: {e}")
            return []
        except Exception as e:
            from bot import logger
            logger.log(
                "GPT_ERROR",
                f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}"
            )
            print_log(message=f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}")
            return []
    return None


async def process_assistant_run(
    client: AsyncOpenAI,
    run,
    thread_id: str,
    user_id: int,
    image_client: Optional[AsyncOpenAIImageClient] = None,
):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—Å–µ tool‚Äëcalls –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏¬†–ø–µ—Ä–µ–¥–∞—ë—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    if run.status != "requires_action" or run.required_action.type != "submit_tool_outputs":
        return
    image_client = image_client or AsyncOpenAIImageClient()
    outputs = []
    final_images = []
    web_answer = None
    text_answer = None
    for tc in run.required_action.submit_tool_outputs.tool_calls:
        if tc.function.name == "search_web" or tc.function.name == "add_notification":
            text_answer = await dispatch_tool_call(tc, image_client, user_id=user_id)
            outputs.append({"tool_call_id": tc.id, "output": json.dumps({"text": web_answer})})
            continue
        images = (await dispatch_tool_call(tc, image_client, user_id=user_id))
        final_images.extend(images)
        if images is None:
            outputs.append({"tool_call_id": tc.id, "output": "ignored"})
            continue
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ —Ñ–∞–π–ª—ã
        file_ids = []
        # if images[1] == "openai":
        for idx, img in enumerate(images):
            file = await client.files.create(file=(f"result_{idx}.png", io.BytesIO(img), "image/png"), purpose="vision")
            file_ids.append(file.id)
        outputs.append({
            "tool_call_id": tc.id,
            "output": json.dumps({"file_ids": file_ids})
        })
    # print(final_images)
    await client.beta.threads.runs.submit_tool_outputs(thread_id=thread_id, run_id=run.id, tool_outputs=outputs)
    # print("—É—Ä–∞, –∫–∞—Ä—Ç–∏–Ω–∫–∞ —Å–¥–µ–ª–∞–Ω–∞")
    await _await_run_done(client=client , thread_id=thread_id, run_id=run.id)
    return {"final_images": final_images, "web_answer": web_answer, "notif_answer": text_answer}
    # return images


async def _await_run_done(client, thread_id: str, run_id: str) -> None:
    TERMINAL = {"completed", "failed", "cancelled", "expired"}
    while True:
        run = await client.beta.threads.runs.retrieve(
            thread_id=thread_id, run_id=run_id
        )
        if run.status in TERMINAL:
            return
        await asyncio.sleep(0.5)

