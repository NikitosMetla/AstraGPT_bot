# gpt_completions.py

from __future__ import annotations

import asyncio
import base64
import io
import json
import os
import traceback
from collections import defaultdict
from typing import Any, Awaitable, Callable, Optional, Sequence, Dict, List, Tuple

import aiohttp
from dotenv import find_dotenv, load_dotenv
from openai import (
    APIConnectionError,
    APIStatusError,
    APITimeoutError,
    AsyncOpenAI,
    AuthenticationError,
    PermissionDeniedError,
    RateLimitError,
    BadRequestError,
)

from settings import get_current_datetime_string, print_log, get_current_bot
from data.keyboards import subscriptions_keyboard, more_generations_keyboard, delete_notification_keyboard
from utils import web_search_agent
from utils.create_notification import (
    schedule_notification,
    NotificationLimitError,
    NotificationFormatError,
    NotificationDateTooFarError,
    NotificationDateInPastError,
    NotificationPastTimeError,
    NotificationTextTooShortError,
    NotificationTextTooLongError,
)
from utils.gpt_images import AsyncOpenAIImageClient
from utils.new_fitroom_api import FitroomClient
from utils.parse_gpt_text import sanitize_with_links
from utils.runway_api import generate_image_bytes

from db.models import Users
from db.repository import (
    users_repository,
    subscriptions_repository,
    type_subscriptions_repository,
    generations_packets_repository,
    notifications_repository, dialogs_messages_repository,
)
from db.models import DialogsMessages

# --- –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---

load_dotenv(find_dotenv())
OPENAI_API_KEY: str | None = os.getenv("GPT_TOKEN") or os.getenv("OPENAI_API_KEY")
DEFAULT_IMAGE_MODEL = "gpt-image-1"
DEFAULT_IMAGE_SIZE = "1024x1024"

_thread_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)

class NoSubscription(Exception):
    pass

class NoGenerations(Exception):
    pass

async def get_thread_lock(user_key: str) -> asyncio.Lock:
    return _thread_locks[user_key]

def _b64(b: bytes) -> str:
    return base64.b64encode(b).decode()

async def _retry(
    fn: Callable[..., Awaitable[Any]],
    *args,
    attempts: int = 6,
    backoff: float = 1.5,
    **kwargs,
):
    for attempt in range(1, attempts + 1):
        try:
            return await fn(*args, **kwargs)
        except (APITimeoutError, APIConnectionError, APIStatusError, RateLimitError):
            if attempt == attempts:
                raise
            await asyncio.sleep(backoff ** attempt)
        except (AuthenticationError, PermissionDeniedError):
            raise

# --- –ü–æ–º–æ—â–Ω–∏–∫–∏ –ø–æ –∞—É–¥–∏–æ ---

async def tts_generate_audio_mp3(text: str) -> io.BytesIO:
    url = "https://api.openai.com/v1/audio/speech"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "gpt-4o-mini-tts",
        "input": text,
        "voice": "shimmer",
        "instructions": "Speak dramatic",
        "response_format": "mp3",
    }
    async with aiohttp.ClientSession() as session:
        async with session.post(url, headers=headers, json=payload, timeout=30) as response:
            if response.status == 200:
                return io.BytesIO(await response.read())
            raise RuntimeError(f"TTS error {response.status}: {await response.text()}")

# --- –ê–¥–∞–ø—Ç–∞—Ü–∏—è tools –∫ Chat Completions ---

def _tools_for_chat_completions(tools: List[dict]) -> List[dict]:
    conv = []
    for t in tools:
        conv.append({
            "type": "function",
            "function": {
                "name": t["name"],
                "description": t.get("description") or "",
                "parameters": t.get("parameters") or {"type": "object", "properties": {}},
                "strict": t.get("strict", False),
            }
        })
    return conv

# --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ ---

class HistoryStore:
    def __init__(self):
        self.repo = dialogs_messages_repository

    async def append(self, user_id: int, payload: dict):
        await self.repo.add_message(user_id=user_id, message=payload)

    async def load(self, user_id: int) -> List[DialogsMessages]:
        return await self.repo.get_messages_by_user_id(user_id=user_id)

# --- –ú–∞–ø–ø–∏–Ω–≥ –∏—Å—Ç–æ—Ä–∏–∏ –≤ Chat Completions messages ---

def _map_history_to_chat_messages(items: List[DialogsMessages]) -> List[dict]:
    msgs: List[dict] = []
    for itm in items:
        try:
            payload = itm.message
            t = payload.get("type")
            if t == "human":
                parts = (payload.get("additional_kwargs") or {}).get("content_parts")
                if parts and isinstance(parts, list):
                    msgs.append({"role": "user", "content": parts})
                else:
                    msgs.append({"role": "user", "content": payload.get("content", "")})
            elif t == "ai":
                tool_calls = payload.get("tool_calls") or []
                message = {
                    "role": "assistant",
                    "content": payload.get("content", "") or None,
                }
                if tool_calls:
                    cc = []
                    for i, tc in enumerate(tool_calls):
                        cc.append({
                            "id": tc.get("id") or f"call_{i}",
                            "type": "function",
                            "function": {
                                "name": tc.get("name"),
                                "arguments": json.dumps(tc.get("arguments") or {}),
                            }
                        })
                    message["tool_calls"] = cc
                msgs.append(message)
                invalids = payload.get("invalid_tool_calls") or []
                if invalids:
                    pass
            elif t == "tool":
                msgs.append({
                    "role": "tool",
                    "tool_call_id": payload.get("tool_call_id", ""),
                    "content": payload.get("content", ""),
                })
        except Exception:
            continue
    return msgs[-50:]

# --- –î–∏—Å–ø–µ—Ç—á–µ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (—Å–æ–≤–º–µ—Å—Ç–∏–º —Å —Ç–≤–æ–µ–π –ª–æ–≥–∏–∫–æ–π) ---

async def dispatch_tool_call(tool_call, image_client, user_id: int, max_photo_generations: int | None = None) -> Any:
    # —Å–æ–≤–º–µ—Å—Ç–∏–º –∫–∞–∫ —Ä–∞–Ω—å—à–µ: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±—ä–µ–∫—Ç–∞/—Å–ª–æ–≤–∞—Ä—è
    if hasattr(tool_call, "function"):
        name = tool_call.function.name
        args_raw = tool_call.function.arguments
        call_id = getattr(tool_call, "id", None)
    else:
        name = tool_call.get("function", {}).get("name") or tool_call.get("name")
        args_raw = tool_call.get("function", {}).get("arguments") or tool_call.get("arguments")
        call_id = tool_call.get("id")

    if isinstance(args_raw, dict):
        args = args_raw
    else:
        try:
            args = json.loads(args_raw)
        except Exception:
            first_obj = (args_raw or "").split('}', 1)[0] + '}'
            args = json.loads(first_obj)

    user = await users_repository.get_user_by_user_id(user_id=user_id)
    photo_bytes = []
    if name == "add_notification":
        when_send_str, text_notification = args.get("when_send_str"), args.get("text_notification")
        try:
            await schedule_notification(user_id=user.user_id, when_send_str=when_send_str, text_notification=text_notification)
            return f"‚úÖ –û—Ç–ª–∏—á–Ω–æ! –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ {when_send_str} –ø–æ –º–æ—Å–∫–æ–≤—Å–∫–æ–º—É –≤—Ä–µ–º–µ–Ω–∏\n\nüìù –¢–µ–∫—Å—Ç –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è: {text_notification}"
        except NotificationLimitError:
            active_notifications = await notifications_repository.get_active_notifications_by_user_id(user_id)
            return (f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π. –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å {len(active_notifications)} –∞–∫—Ç–∏–≤–Ω—ã—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π. –ú–∞–∫—Å–∏–º—É–º: 10.")
        except NotificationFormatError:
            return "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ì–ì–ì–ì-–ú–ú-–î–î –ß–ß:–ú–ú:–°–°"
        except NotificationDateTooFarError:
            return "‚ùå –î–∞—Ç–∞ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–∞—è. –î–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –¥–æ 2030 –≥–æ–¥–∞."
        except NotificationDateInPastError:
            return "‚ùå –£–∫–∞–∑–∞–Ω–Ω—ã–π –≥–æ–¥ —É–∂–µ –ø—Ä–æ—à—ë–ª."
        except NotificationPastTimeError:
            return "‚ùå –í—Ä–µ–º—è —É–∂–µ –ø—Ä–æ—à–ª–æ. –£–∫–∞–∂–∏—Ç–µ –±—É–¥—É—â–µ–µ –≤—Ä–µ–º—è."
        except NotificationTextTooShortError:
            return "‚ùå –¢–µ–∫—Å—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (>=3 —Å–∏–º–≤–æ–ª–æ–≤)."
        except NotificationTextTooLongError:
            return "‚ùå –¢–µ–∫—Å—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (<=500 —Å–∏–º–≤–æ–ª–æ–≤)."
        except Exception:
            return "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."

    if name == "search_web":
        query = args.get("query") or ""
        return await web_search_agent.search_prompt(query)

    if user.last_image_id is not None:
        for photo_id in user.last_image_id.split(", "):
            main_bot = get_current_bot()
            photo_bytes_io = io.BytesIO()
            try:
                await main_bot.download(photo_id, destination=photo_bytes_io)
                photo_bytes_io.seek(0)
                photo_bytes.append(photo_bytes_io.read())
            except:
                pass

    if name == "generate_image":
        try:
            kwargs: dict[str, Any] = {
                "prompt": args["prompt"],
                "n": args.get("n", 1) if (max_photo_generations and max_photo_generations > args.get("n", 1)) else args.get("n", 1),
                "size": args.get("size", DEFAULT_IMAGE_SIZE),
                "quality": args.get("quality", "low"),
            }
            if args.get("edit_existing_photo"):
                kwargs["images"] = [("image.png", io.BytesIO(photo), "image/png") for photo in photo_bytes]
            return await image_client.generate(**kwargs)
        except:
            return []

    if name == "fitting_clothes":
        fitroom_client = FitroomClient()
        cloth_type = (args.get("cloth_type") or "full").strip()
        swap_photos = args.get("swap_photos") or False
        if len(photo_bytes) != 2:
            return "–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, –ø—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ –∏ —Ñ–æ—Ç–æ –æ–¥–µ–∂–¥—ã –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º! –†–æ–≤–Ω–æ –¥–≤–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏!"
        if swap_photos:
            model_bytes = photo_bytes[1]
            cloth_bytes = photo_bytes[0]
        else:
            model_bytes = photo_bytes[0]
            cloth_bytes = photo_bytes[1]
        try:
            main_bot = get_current_bot()
            result_bytes = await fitroom_client.try_on(
                model_bytes=model_bytes,
                cloth_bytes=cloth_bytes,
                cloth_type=cloth_type,
                send_bot=main_bot,
                chat_id=user_id,
                validate=False,
            )
            return [result_bytes]
        except Exception:
            return []
        finally:
            try:
                await fitroom_client.close()
            except:
                pass

    if name == "edit_image_only_with_peoples":
        try:
            prompt = (args.get("prompt") or "").strip()[:400]
            prompt = prompt.encode("ascii", "ignore").decode()
            if not prompt:
                return []
            return [await generate_image_bytes(prompt=args.get("prompt"), ratio=args.get("ratio"),
                                               images=photo_bytes if len(photo_bytes) <= 3 else photo_bytes[:3])]
        except Exception:
            return []

    return None

# --- –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ tool-calls –≤ —Ä–µ–∂–∏–º–µ Chat Completions ---

async def run_tools_and_followup_chat(
    client: AsyncOpenAI,
    model: str,
    messages: List[dict],
    tool_calls: List[dict],
    user_id: int,
    max_photo_generations: int,
) -> Tuple[List[bytes], Optional[str], Optional[str], List[dict]]:
    image_client = AsyncOpenAIImageClient()
    outputs_messages: List[dict] = []
    final_images: List[bytes] = []
    web_answer = None
    notif_answer = None
    images_counter = 0

    main_bot = get_current_bot()
    from settings import sub_text
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user.user_id)
    type_sub = await type_subscriptions_repository.get_type_subscription_by_id(type_id=user_sub.type_subscription_id) if user_sub else None
    sub_types = await type_subscriptions_repository.select_all_type_subscriptions()

    delete_message = None
    for tc in tool_calls:
        fname = tc["function"]["name"]
        if user_sub is None or (type_sub is not None and type_sub.plan_name == "Free"):
            if fname not in ("search_web", "add_notification"):
                await main_bot.send_message(chat_id=user.user_id,
                                            text="üö® –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –ø–æ –ø–æ–¥–ø–∏—Å–∫–µ\n\n" + sub_text,
                                            reply_markup=subscriptions_keyboard(sub_types).as_markup())
                raise NoSubscription(f"User {user.user_id} dont has active subscription")

        if fname == "search_web":
            delete_message = await main_bot.send_message(text="üîç–ù–∞—á–∞–ª –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—ã...",
                                                         chat_id=user.user_id)
        elif fname == "add_notification":
            delete_message = await main_bot.send_message(text="üñå–ù–∞—á–∞–ª –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ...",
                                                         chat_id=user.user_id)
        else:
            if user_sub.photo_generations <= 0:
                generations_packets = await generations_packets_repository.select_all_generations_packets()
                from settings import buy_generations_text
                if type_sub and type_sub.plan_name == "Free":
                    await main_bot.send_message(chat_id=user.user_id,
                                                text="üö® –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –ø–æ –ø–æ–¥–ø–∏—Å–∫–µ\n\n" + sub_text,
                                                reply_markup=subscriptions_keyboard(sub_types).as_markup())
                    raise NoSubscription(f"User {user.user_id} dont has active subscription")
                await main_bot.send_message(chat_id=user_id, text=buy_generations_text,
                                            reply_markup=more_generations_keyboard(generations_packets).as_markup())
                raise NoGenerations(f"User {user.user_id} dont has generations")
            delete_message = await main_bot.send_message(chat_id=user.user_id,
                                                         text="üé®–ù–∞—á–∞–ª —Ä–∞–±–æ—Ç—É –Ω–∞–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º, –Ω–µ–º–Ω–æ–≥–æ –º–∞–≥–∏–∏‚Ä¶")
        break

    try:
        for tc in tool_calls:
            fname = tc["function"]["name"]
            tool_id = tc.get("id") or ""
            result = await dispatch_tool_call(tc, image_client, user_id=user_id, max_photo_generations=max_photo_generations)

            if fname == "search_web":
                web_answer = result
                outputs_messages.append({"role": "tool", "tool_call_id": tool_id, "content": json.dumps({"text": web_answer}, ensure_ascii=False)})
                continue

            if fname == "add_notification":
                notif_answer = result
                outputs_messages.append({"role": "tool", "tool_call_id": tool_id, "content": json.dumps({"text": notif_answer}, ensure_ascii=False)})
                continue

            if isinstance(result, str):
                outputs_messages.append({"role": "tool", "tool_call_id": tool_id, "content": json.dumps({"text": result}, ensure_ascii=False)})
                continue

            if result is None:
                outputs_messages.append({"role": "tool", "tool_call_id": tool_id, "content": "ignored"})
                continue

            if isinstance(result, list):
                if images_counter >= max_photo_generations:
                    outputs_messages.append({"role": "tool", "tool_call_id": tool_id, "content": "–õ–∏–º–∏—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –∏—Å—á–µ—Ä–ø–∞–Ω"})
                    continue
                images_counter += len(result)
                final_images.extend(result)
                file_ids = []
                for idx, img in enumerate(result):
                    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª –≤ Files API (purpose=vision), —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å ids –≤ —Ç–µ–∫—Å—Ç
                    f = await client.files.create(file=(f"result_{idx}.png", io.BytesIO(img), "image/png"), purpose="vision")
                    file_ids.append(f.id)
                outputs_messages.append({"role": "tool", "tool_call_id": tool_id,
                                         "content": json.dumps({"file_ids": file_ids}, ensure_ascii=False)})
            else:
                outputs_messages.append({"role": "tool", "tool_call_id": tool_id, "content": "ok"})
    finally:
        if delete_message:
            try:
                await delete_message.delete()
            except:
                pass

    followup_messages = messages + outputs_messages
    comp2 = await client.chat.completions.create(
        model=model,
        messages=followup_messages,
        temperature=0.7,
    )

    content_text = (comp2.choices[0].message.content or "").strip()
    if notif_answer and "‚úÖ" in notif_answer:
        user_notifications = await notifications_repository.get_active_notifications_by_user_id(user_id=user_id)
        # –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –≤–µ—Ä–Ω—ë–º —É–∂–µ –≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –∫–æ–¥–µ
    return final_images, web_answer, notif_answer, [comp2.choices[0].message.model_dump()]

# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ user-—Å–æ–æ–±—â–µ–Ω–∏—è (—Ç–µ–∫—Å—Ç/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–¥–æ–∫—É–º–µ–Ω—Ç—ã/–∞—É–¥–∏–æ) ---

async def build_user_content_for_chat(
    client: AsyncOpenAI,
    text: str,
    image_bytes: Sequence[io.BytesIO] | None,
    document_bytes: Sequence[tuple[io.BytesIO, str, str]] | None,
    audio_bytes: io.BytesIO | None,
) -> List[dict]:
    # Chat Completions: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äì —á–µ—Ä–µ–∑ image_url base64, –¥–æ–∫—É–º–µ–Ω—Ç—ã ‚Äì –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ
    photos: List[dict] = []
    content = []
    image_names = []
    if image_bytes:
        for idx, img_io in enumerate(image_bytes):
            img_io.seek(0)
            b = img_io.read()
            image_names.append(f"image_{idx}.png")
            photos.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{_b64(b)}"
                }
            })

    text_final = f"–°–µ–≥–æ–¥–Ω—è - {get_current_datetime_string()} –ø–æ –ú–æ—Å–∫–≤–µ.\n\n{text or '–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'}"
    if image_names:
        text_final += f"\n\n–í–æ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {', '.join(image_names)}"

    if document_bytes:
        text_final += "\n\n–í–æ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —è –ø—Ä–∏–∫—Ä–µ–ø–∏–ª:\n"
        for idx, (doc_io, file_name, mime_ext) in enumerate(document_bytes):
            doc_io.seek(0)
            doc_file = await client.files.create(
                file=(f"{file_name}", doc_io, f"application/{mime_ext}"),
                purpose="user_data",
            )
            text += f"{file_name} "
            content.append({
                "type": "file",
                "file": {"file_id": doc_file.id, "filename": file_name + "." + mime_ext},

            })
    content.append({"type": "text", "text": text_final})
    # Chat API –æ–∂–∏–¥–∞–µ—Ç —Å—Ç—Ä–æ–∫—É content –ª–∏–±–æ –º–∞—Å—Å–∏–≤ —á–∞—Å—Ç–µ–π —Å —Ç–µ–∫—Å—Ç–æ–º/–∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏.
    if photos:
        content.extend(photos)
    return content   # —á–∏—Å—Ç–æ —Ç–µ–∫—Å—Ç

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ Assistants‚ÜíCompletions ---

class GPTCompletions:  # noqa: N801
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        self.history = HistoryStore()

    async def _reset_client(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)

    async def send_message(
        self,
        user_id: int,
        thread_id: str | None = None,      # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        *,
        with_audio_transcription: bool = False,
        text: str | None = None,
        image_bytes: Sequence[io.BytesIO] | None = None,
        document_bytes: Sequence[tuple[io.BytesIO, str, str]] | None = None,
        document_type: str | None = None,
        audio_bytes: io.BytesIO | None = None,
        user_data: Users | None = None,
    ):
        final_content = {
            "text": None,
            "image_files": [],
            "files": [],
            "audio_file": None,
            "reply_markup": None
        }
        main_bot = get_current_bot()
        from bot import logger
        from settings import get_weekday_russian

        user = await users_repository.get_user_by_user_id(user_id=user_id)
        about_user = user.context

        # 1) –≥—Ä—É–∑–∏–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ –ë–î –∏ —Å—Ç—Ä–æ–∏–º messages
        stored = await self.history.load(user_id=user_id)
        messages = _map_history_to_chat_messages(stored)

        # 2) system-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (–∫–∞–∫ —Ä–∞–Ω—å—à–µ –≤ run.instructions)
        system_text = (
            "–í–ê–ñ–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –í–†–ï–ú–ï–ù–ò:\n"
            f"–¢–µ–∫—É—â–∏–µ –¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤ –ú–æ—Å–∫–≤–µ: {get_current_datetime_string()}\n"
            f"–°–µ–≥–æ–¥–Ω—è {get_weekday_russian()}\n"
            "–í–°–ï —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–º –≤—Ä–µ–º–µ–Ω–∏!\n"
            "–ü—Ä–∏–º–µ—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞—Ç:\n"
            "- '–∑–∞–≤—Ç—Ä–∞' = —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å –ø–æ—Å–ª–µ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ\n"
            "- '–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞' = —á–µ—Ä–µ–∑ –¥–≤–∞ –¥–Ω—è\n"
            "- '–Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫' = –±–ª–∏–∂–∞–π—à–∏–π –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –ø–æ—Å–ª–µ —Ç–µ–∫—É—â–µ–π –Ω–µ–¥–µ–ª–∏\n"
            "- '—á–µ—Ä–µ–∑ 30 –º–∏–Ω—É—Ç' = –¥–æ–±–∞–≤–∏—Ç—å 30 –º–∏–Ω—É—Ç –∫ —Ç–µ–∫—É—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏\n\n"
        )
        if about_user:
            system_text += f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n{about_user}\n\n"
        messages = [{"role": "system", "content": system_text}] + messages

        # 3) –≤—Ö–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if not any([text, image_bytes, document_bytes, audio_bytes]):
            final_content["text"] = "–ù–µ –ø–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
            return final_content

        content = await build_user_content_for_chat(
            self.client,
            text or "",
            image_bytes=image_bytes,
            document_bytes=document_bytes,
            audio_bytes=audio_bytes,
        )
        messages.append({"role": "user", "content": content})

        # 4) —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Ö–æ–¥ –∫–∞–∫ JSON –≤ –ë–î
        human_json = {
            "type": "human",
            "content": content[0].get("text") if content and isinstance(content[0], dict) else (text or ""),
            "additional_kwargs": {"content_parts": content},  # ‚Üê —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å—å –º–∞—Å—Å–∏–≤ —á–∞—Å—Ç–µ–π
            "response_metadata": {},
        }


        # 5) –≤—ã–∑–æ–≤ Chat Completions
        lock = await get_thread_lock(str(user_id))
        async with lock:
            try:
                from settings import tools
                tools_payload = _tools_for_chat_completions(tools or [])
                comp = await self.client.chat.completions.create(
                    model=user.model_type,
                    messages=messages,
                    tools=tools_payload if tools_payload else None,
                    temperature=0.7,
                )
                await self.history.append(user_id=user_id, payload=human_json)
                msg = comp.choices[0].message
                tool_calls = getattr(msg, "tool_calls", None) or msg.model_extra.get("tool_calls") if hasattr(msg, "model_extra") else None

                # 6) –µ—Å–ª–∏ —Ç—É–ª–∑—ã —Ç—Ä–µ–±—É—é—Ç—Å—è ‚Äî –≤—ã–ø–æ–ª–Ω–∏–º –∏ –≤—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å
                if tool_calls:
                    # –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–ø–∏—Å–æ–∫/–ª–∏–º–∏—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ run_tools_and_followup_chat
                    user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user.user_id)
                    max_photo_generations = user_sub.photo_generations if user_sub else 0
                    final_images, web_answer, notif_answer, assistant_msgs = await run_tools_and_followup_chat(
                        client=self.client,
                        model=user.model_type,
                        messages=messages + [{"role": "assistant", "content": msg.content or None, "tool_calls": [tc.model_dump() for tc in tool_calls]}],
                        tool_calls=[tc.model_dump() for tc in tool_calls],
                        user_id=user.user_id,
                        max_photo_generations=max_photo_generations,
                    )

                    # –≤—ã–¥–∞—á–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                    if web_answer:
                        final_text = sanitize_with_links(web_answer)
                        ai_json = {
                            "type": "ai",
                            "content": final_text,
                            "tool_calls": [],
                            "additional_kwargs": {},
                            "response_metadata": {},
                            "invalid_tool_calls": [],
                        }
                        await self.history.append(user_id=user_id, payload=ai_json)
                        final_content["text"] = final_text
                        return final_content

                    if notif_answer:
                        final_text = sanitize_with_links(notif_answer)
                        ai_json = {
                            "type": "ai",
                            "content": final_text,
                            "tool_calls": [],
                            "additional_kwargs": {},
                            "response_metadata": {},
                            "invalid_tool_calls": [],
                        }
                        await self.history.append(user_id=user_id, payload=ai_json)
                        final_content["text"] = final_text
                        if "‚úÖ" in final_text:
                            user_notifications = await notifications_repository.get_active_notifications_by_user_id(user_id=user_id)
                            final_content["reply_markup"] = delete_notification_keyboard(user_notifications[-1].id)
                        return final_content

                    if final_images:
                        # –°–ø–∏—Å–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π
                        if user_sub:
                            await subscriptions_repository.use_generation(subscription_id=user_sub.id, count=len(final_images))
                        # –¢–µ–∫—Å—Ç –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                        assistant_text = assistant_msgs[0].get("content") or "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
                        final_text = sanitize_with_links(assistant_text)
                        ai_json = {
                            "type": "ai",
                            "content": final_text,
                            "tool_calls": [],
                            "additional_kwargs": {},
                            "response_metadata": {},
                            "invalid_tool_calls": [],
                        }
                        await self.history.append(user_id=user_id, payload=ai_json)
                        final_content["text"] = final_text
                        final_content["image_files"] = final_images
                        return final_content

                    # –µ—Å–ª–∏ —Ç—É–ª–∑—ã –æ—Ç—Ä–∞–±–æ—Ç–∞–ª–∏, –Ω–æ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–µ—Ä–Ω—É–ª–∏ –æ—â—É—Ç–∏–º–æ–≥–æ
                    final_text = (assistant_msgs[0].get("content") or "").strip() or "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å."
                    final_text = sanitize_with_links(final_text)
                    ai_json = {
                        "type": "ai",
                        "content": final_text,
                        "tool_calls": [],
                        "additional_kwargs": {},
                        "response_metadata": {},
                        "invalid_tool_calls": [],
                    }
                    await self.history.append(user_id=user_id, payload=ai_json)
                    final_content["text"] = final_text
                    return final_content

                # 7) –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –±–µ–∑ —Ç—É–ª–∑–æ–≤
                message_text = msg.content or ""
                if with_audio_transcription:
                    audio_data = await tts_generate_audio_mp3(message_text)
                    final_text = sanitize_with_links(message_text)
                    ai_json = {
                        "type": "ai",
                        "content": final_text,
                        "tool_calls": [],
                        "additional_kwargs": {},
                        "response_metadata": {},
                        "invalid_tool_calls": [],
                    }
                    await self.history.append(user_id=user_id, payload=ai_json)
                    final_content["text"] = final_text
                    final_content["audio_file"] = audio_data
                    return final_content

                final_text = sanitize_with_links(message_text)
                ai_json = {
                    "type": "ai",
                    "content": final_text,
                    "tool_calls": [],
                    "additional_kwargs": {},
                    "response_metadata": {},
                    "invalid_tool_calls": [],
                }
                await self.history.append(user_id=user_id, payload=ai_json)
                final_content["text"] = final_text
                return final_content

            except NoSubscription:
                raise
            except NoGenerations:
                raise
            except Exception:
                await self._reset_client()
                logger.log("GPT_ERROR", f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}")
                print_log(message=f"{user_id} | –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ gpt: {traceback.format_exc()}")
                final_content["text"] = ("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑! "
                                         "–¢–≤–æ–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                return final_content

    @staticmethod
    async def transcribe_audio(audio_bytes: io.BytesIO, language: str = "ru") -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper."""
        url = "https://api.openai.com/v1/audio/transcriptions"
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}

        audio_bytes.name = "audio.mp3"
        data = {"file": audio_bytes, "model": "whisper-1", "language": language}

        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, data=data, timeout=60) as response:
                if response.status == 200:
                    result = await response.json()
                    return result.get("text", "")
                raise RuntimeError(f"Transcription error {response.status}: {await response.text()}")
