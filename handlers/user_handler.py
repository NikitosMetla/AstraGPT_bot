import io
import pprint
import traceback

from aiogram import Router, F, Bot, types
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import any_state
from aiogram.types import Message, CallbackQuery, BufferedInputFile, InputMediaPhoto
from aiogram_media_group import media_group_handler

from data.keyboards import profiles_keyboard, cancel_keyboard, settings_keyboard, \
    confirm_clear_context, buy_sub_keyboard, subscriptions_keyboard, delete_payment_keyboard, unlink_card_keyboard
from db.repository import users_repository, ai_requests_repository, subscriptions_repository
from settings import InputMessage, photos_pages, OPENAI_ALLOWED_DOC_EXTS, gpt_assistant
from utils.paginator import MechanicsPaginator
from utils.parse_gpt_text import split_telegram_html, sanitize_with_links

standard_router = Router()


@standard_router.callback_query(F.data == "delete_payment", any_state)
@standard_router.message(F.text == "/unlink_card", any_state)
async def sub_message(message: Message | CallbackQuery, state: FSMContext, bot: Bot):
    user_id = message.from_user.id
    user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user_id)
    if type(message) == Message:
        if user_sub is None:
            await message.answer("‚ú®–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —É —Ç–µ–±—è –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–∏ –∏ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏")
            return
        await message.answer("–¢—ã —É–≤–µ—Ä–µ–Ω, —á—Ç–æ —Ö–æ—á–µ—à—å –æ—Ç–≤—è–∑–∞—Ç—å –∫–∞—Ä—Ç—É –¥–ª—è –æ–ø–ª–∞—Ç—ã –ø–æ–¥–ø–∏—Å–∫–∏? –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ"
                             " —Ç–≤–æ—è –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–µ —Å–º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–ª–µ–≤–∞—Ç—å—Å—è",
                             reply_markup=unlink_card_keyboard.as_markup())
    else:
        if user_sub is None:
            await message.message.answer("‚ú®–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —É —Ç–µ–±—è –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–∏ –∏ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏")
            return
        await message.message.delete()
        await message.message.answer("–¢—ã —É–≤–µ—Ä–µ–Ω, —á—Ç–æ —Ö–æ—á–µ—à—å –æ—Ç–≤—è–∑–∞—Ç—å –∫–∞—Ä—Ç—É –¥–ª—è –æ–ø–ª–∞—Ç—ã –ø–æ–¥–ø–∏—Å–∫–∏? –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ"
                             " —Ç–≤–æ—è –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–µ —Å–º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–ª–µ–≤–∞—Ç—å—Å—è",
                             reply_markup=unlink_card_keyboard.as_markup())


@standard_router.callback_query(F.data == "unlink_card", any_state)
async def sub_message(call: CallbackQuery, state: FSMContext, bot: Bot):
    user_id = call.from_user.id
    user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user_id)
    if user_sub is None or user_sub.plan_name == "Free":
        await call.message.answer(
            "‚ú®–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —É —Ç–µ–±—è –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–∏ –∏ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏")
        return
    if user_sub.method_id is None:
        await call.message.answer(
            "‚ú®–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —É —Ç–µ–±—è —É–∂–µ –Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω–∞ –Ω–∏–∫–∞–∫–∞—è –∫–∞—Ä—Ç–∞")
        return
    await subscriptions_repository.delete_payment_method(subscription_id=user_sub.id)
    await call.message.delete()
    await call.message.answer("–û—Ç–ª–∏—á–Ω–æ, –æ—Ç–≤—è–∑–∞–ª–∏ —Ç–≤–æ–π –º–µ—Ç–æ–¥ –æ–ø–ª–∞—Ç—ã. –¢–µ–ø–µ—Ä—å —Ç–≤–æ—è –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–µ —Å–º–æ–∂–µ—Ç –ø—Ä–æ–¥–ª–µ–≤–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")


@standard_router.message(F.text == "/subscribe", any_state)
async def sub_message(message: Message, state: FSMContext, bot: Bot):
    user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=message.from_user.id)
    if user_sub is not None:
        await message.answer("""üîì –û—Ç–∫—Ä–æ–π—Ç–µ –≤–µ—Å—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –Ω–∞—à–µ–≥–æ –ò–ò-–±–æ—Ç–∞ ‚Äî –æ—Ñ–æ—Ä–º–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É –ø—Ä—è–º–æ –∑–¥–µ—Å—å.
    
    –¢–∞—Ä–∏—Ñ—ã
    ‚Ä¢ Smart ‚Äî 499 ‚ÇΩ/–º–µ—Å: –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ GPT-4o-mini (–¥–æ 1 000 —Å–æ–æ–±—â–µ–Ω–∏–π).
    ‚Ä¢ Pro ‚Äî 999 ‚ÇΩ/–º–µ—Å: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∫–∞–Ω–∞–ª –∫ GPT-4o –∏ –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∞ —Ç–∞–∫–∂–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π gpt-image-1.
    
    üìÖ –ü–æ–¥–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ, –æ—Ç–º–µ–Ω–∏—Ç—å –º–æ–∂–Ω–æ –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç.
    
    üòä –í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —É—Ä–æ–≤–µ–Ω—å –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–û–ø–ª–∞—Ç–∏—Ç—å¬ª ‚Äî –º—ã —É–∂–µ –≥–æ—Ç–æ–≤—ã –ø–æ–º–æ—á—å!""",
                             reply_markup=buy_sub_keyboard.as_markup())
    else:
        await message.answer("–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥, –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —É —Ç–µ–±—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø–æ–¥–ø–∏—Å–∫–∞."
                             " –ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å –æ—Ç–≤—è–∑–∞—Ç—å –∫–∞—Ä—Ç—É, —Ç–æ –Ω–∞–∂–º–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ",
                             reply_markup=delete_payment_keyboard.as_markup())


@standard_router.callback_query(F.data == "buy_sub")
async def choice_sub_message(call: CallbackQuery, state: FSMContext):
    await call.message.delete()
    await call.message.answer("""–í—ã–±–µ—Ä–∏ —Ç–∏–ø –ø–æ–¥–ø–∏—Å–∫–∏, –∫–æ—Ç–æ—Ä—É—é —Ö–æ—á–µ—à—å –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏:
–¢–∞—Ä–∏—Ñ—ã
    ‚Ä¢ Smart ‚Äî 499 ‚ÇΩ/–º–µ—Å: –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ GPT-4o-mini (–¥–æ 1 000 —Å–æ–æ–±—â–µ–Ω–∏–π).
    ‚Ä¢ Pro ‚Äî 999 ‚ÇΩ/–º–µ—Å: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∫–∞–Ω–∞–ª –∫ GPT-4o –∏ –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∞ —Ç–∞–∫–∂–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π gpt-image-1.""",
                              reply_markup=subscriptions_keyboard.as_markup())



@standard_router.callback_query(F.data.startswith("mechanics_paginator"))
async def get_page_paginator(call: CallbackQuery, state: FSMContext):
    call_data = call.data.split(":")
    page_now = int(call_data[2])
    paginator = MechanicsPaginator(page_now)
    if call_data[1] == "page_prev_keys":
        keyboard = paginator.generate_prev_page()
        await call.message.edit_media(media=InputMediaPhoto(media=photos_pages.get(paginator.page_now)),
                                      reply_markup=keyboard)

    elif call_data[1] == "page_next_keys":
        keyboard = paginator.generate_next_page()
        await call.message.edit_media(media=InputMediaPhoto(media=photos_pages.get(paginator.page_now)),
                                      reply_markup=keyboard)


@standard_router.message(F.text == "/instructions", any_state)
@standard_router.message(F.text == "/start", any_state)
async def send_user_message(message: Message, state: FSMContext, bot: Bot, user_data):
    paginator = MechanicsPaginator(page_now=1)
    keyboard = paginator.generate_now_page()
    await message.answer_photo(photo=photos_pages.get(paginator.page_now),
                               reply_markup=keyboard)


@standard_router.message(F.text == "/profile", any_state)
async def send_user_message(message: Message, state: FSMContext, bot: Bot):
    await message.answer('üë§ –¢–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å\n\n‚úì –ü–æ–¥–ø–∏—Å–∫–∞: –ê–∫—Ç–∏–≤–Ω–∞ ‚àû (–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)\n‚úì –î–æ—Å—Ç—É–ø: –ü–æ–ª–Ω—ã–π'
                         ' –∫–æ –≤—Å–µ–º —Ñ—É–Ω–∫—Ü–∏—è–º\n\n‚ú® –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è\n–•–æ—á–µ—à—å –∏–¥–µ–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã? –†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ –≤ '
                         '"–ù–∞—Å—Ç—Ä–æ–π–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"! –ë–æ—Ç —É—á—Ç—ë—Ç —ç—Ç–æ –Ω–∞–ø—Ä–∏–º–µ—Ä –ø—Ä–∏:\n- –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —Ä–µ–∑—é–º–µ\n- '
                         '–ù–∞–ø–∏—Å–∞–Ω–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤\n- –î–∞—á–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n\n–ß–µ–º –±–æ–ª—å—à–µ –∑–Ω–∞–µ—Ç –±–æ—Ç ‚Äî —Ç–µ–º —Ç–æ—á–Ω–µ–µ –ø–æ–º–æ–≥–∞–µ—Ç!',
                         reply_markup=profiles_keyboard.as_markup())


@standard_router.message(F.text == "/clear_context", any_state)
async def send_user_message(message: Message, state: FSMContext, bot: Bot):
    await message.answer('–¢—ã —É–≤–µ—Ä–µ–Ω, —á—Ç–æ —Ö–æ—á–µ—à—å –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞?',
                         reply_markup=confirm_clear_context.as_markup())

@standard_router.callback_query(F.data == "clear_context", any_state)
async def send_user_message(call: CallbackQuery, state: FSMContext, bot: Bot):
    user_id = call.from_user.id
    await users_repository.update_thread_id_by_user_id(user_id=user_id, thread_id=None)
    await call.message.delete()
    await call.message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–≤–æ–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω‚ú®")

@standard_router.callback_query(F.data == "not_clear_context", any_state)
async def send_user_message(call: CallbackQuery, state: FSMContext, bot: Bot):
    await call.message.delete()


@standard_router.message(F.text == "/settings", any_state)
async def send_user_message(message: Message, state: FSMContext, bot: Bot):
    await message.answer('üë§ ü§ñ –í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã\n\n‚Ä¢ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π ‚Äî –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ'
                         ' –≤–æ–ø—Ä–æ—Å—ã üòé\n‚Ä¢ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ‚Äî –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –∫–æ–¥ –∏ —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã üß†\n\n–ü—Ä–æ—Å—Ç–æ'
                         ' –Ω–∞–∂–º–∏ –Ω–∞ –Ω—É–∂–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî –∏ –º—ã —Å—Ä–∞–∑—É –ø–æ–º–æ–∂–µ–º!',
                         reply_markup=settings_keyboard.as_markup())


@standard_router.callback_query(F.data == "edit_user_context", any_state)
async def send_user_message(call: CallbackQuery, state: FSMContext, bot: Bot):
    user = await users_repository.get_user_by_user_id(user_id=call.from_user.id)
    delete_message = await call.message.answer(f"AstraGPT –∑–∞–ø–æ–º–Ω–∏—Ç –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä—É—é –≤—ã —Å–µ–π—á–∞—Å"
                              f" –≤–≤–µ–¥–µ—Ç–µ –∏ –±—É–¥–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –µ–µ –ø—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –≤–∞—Å!\n\n–í–∞—à –Ω—ã–Ω–µ—à–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n{user.context}",
                              reply_markup=cancel_keyboard.as_markup())
    await state.set_state(InputMessage.enter_user_context_state)
    await call.message.delete()
    await state.update_data(delete_message_id=delete_message.message_id)


@standard_router.callback_query(F.data.startswith("mode|"), any_state)
async def send_user_message(call: CallbackQuery, state: FSMContext, bot: Bot):
    mode = call.data.split("|")[1]
    chat = await bot.get_chat(call.from_user.id)
    pinned = chat.pinned_message
    if pinned is not None:
        result= await bot.unpin_chat_message(
            chat_id=call.from_user.id,
            message_id=pinned.message_id  # ID –æ—Ç–∫—Ä–µ–ø–ª—è–µ–º–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        )
    if mode == "universal":
        await users_repository.update_model_type_by_user_id(model_type="gpt-4.1-nano", user_id=call.from_user.id)
        pin_message = await call.message.answer("–ê–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å - ü§ñ–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è")
    else:
        await users_repository.update_model_type_by_user_id(model_type="gpt-4.1", user_id=call.from_user.id)
        pin_message = await call.message.answer("–ê–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å - üß†–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è")
    await pin_message.pin()
    await call.message.delete()


@standard_router.callback_query(F.data == "cancel", any_state)
async def send_user_message(call: CallbackQuery, state: FSMContext, bot: Bot):
    await state.clear()
    await call.message.delete()


@standard_router.message(F.text, InputMessage.enter_user_context_state)
async def standard_message_handler(message: Message, state: FSMContext, bot: Bot):
    state_data = await state.get_data()
    await state.clear()
    delete_message_id = state_data.get('delete_message_id')
    await bot.delete_message(message_id=delete_message_id, chat_id=message.from_user.id)
    await users_repository.update_context_by_user_id(user_id=message.from_user.id, user_context=message.text)
    await message.answer("–û—Ç–ª–∏—á–Ω–æ, —Ç–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")



@standard_router.message(F.text)
async def standard_message_handler(message: Message, bot: Bot):
    text = message.text
    user_id = message.from_user.id
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    # if user is not None and user.full_registration:
    # user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user_id)
    # if user_sub is None:
    #     await message.answer("–ß—Ç–æ–±—ã –æ–±—â–∞—Ç—å—Å—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º GPT —É —Ç–µ–±—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–¥–ø–∏—Å–∫–∞",
    #                          reply_markup=buy_sub_keyboard.as_markup())
    #     return
    # delete_message = await message.reply("–§–æ—Ä–º—É–ª–∏—Ä—É—é –æ—Ç–≤–µ—Ç, —ç—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ –±–æ–ª–µ–µ 5 —Å–µ–∫—É–Ω–¥")
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    ai_answer = await gpt_assistant.send_message(user_id=user_id,
                                                 thread_id=user.standard_ai_threat_id,
                                                 text=text,
                                                 user_data=user)
    images = []
    if type(ai_answer) == dict and ai_answer.get("filename"):
        try:
            await message.reply_document(document=BufferedInputFile(file=ai_answer.get("bytes"),
                                                                     filename=ai_answer.get("filename")))
            ai_answer = "ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"
        except:
            print(traceback.format_exc())
            await message.answer("–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
            return
    elif type(ai_answer) == dict:
        images = ai_answer.get("images")
        ai_answer = ai_answer.get("text")

    # print(ai_answer)
    ai_answer = sanitize_with_links(ai_answer)
    # pprint.pprint(ai_answer)
    # print(ai_answer)
    await ai_requests_repository.add_request(user_id=user.user_id,
                                             answer_ai=ai_answer if ai_answer is not None and ai_answer != "" else "–í—ã–¥–∞–ª —Ñ–∞–π–ª –∏–ª–∏ —Ñ–æ—Ç–æ",
                                             user_question=text,
                                             generate_images=True if len(images) > 0 else False
                                             )
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    from aiogram.enums import ParseMode
    if len(images) == 0:
        split_messages = split_telegram_html(ai_answer)
        print("\n\n")
        # pprint.pprint(split_messages)
        for chunk in split_messages:
            await message.reply(
                chunk,
                disable_web_page_preview=True,
                parse_mode=ParseMode.HTML
            )
        return
    else:
        raw = images[0]
        buffer = io.BytesIO(raw)
        buffer.seek(0)

        photo = BufferedInputFile(file=buffer.getvalue(), filename="image.png")
        message = await message.reply_photo(text=ai_answer,
            parse_mode=ParseMode.HTML,  # ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
            disable_web_page_preview=True,
            photo=photo) # —á—Ç–æ–±—ã –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –ª–∏—à–Ω–∏–µ –ø—Ä–µ–≤—å—é
        await users_repository.update_last_photo_id_by_user_id(photo_id=message.photo[-1].file_id, user_id=user_id)



@standard_router.message(
    F.media_group_id,                 # —Ç–æ–ª—å–∫–æ –∞–ª—å–±–æ–º—ã
    F.content_type == "photo"         # —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
)
@media_group_handler                  # —Å–æ–±–∏—Ä–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫
async def handle_photo_album(messages: list[types.Message], bot: Bot):
    first = messages[0]
    user_id = first.from_user.id
    await bot.send_chat_action(chat_id=first.chat.id, action="typing")
    user = await users_repository.get_user_by_user_id(user_id=user_id)

    # –û–±—â–∏–π caption Telegram –ø—Ä–∏—Å—ã–ª–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ –∞–ª—å–±–æ–º–∞‚ÄÇ
    text = "\n".join([message.caption for message in messages if message.caption is not None])
    # print(text)
    # –°–∫–∞—á–∏–≤–∞–µ–º –≤—Å–µ —Ñ–æ—Ç–æ ‚Üí BytesIO
    image_buffers: list[io.BytesIO] = []
    photo_ids: list[str] = []
    for msg in messages:
        buf = io.BytesIO()
        await bot.download(msg.photo[-1], destination=buf)
        image_buffers.append(buf)
        photo_ids.append(msg.photo[-1].file_id)
        print(msg.photo[-1].file_id)
    await users_repository.update_last_photo_id_by_user_id(photo_id=", ".join(photo_ids), user_id=user_id)
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–µ—Å—å —Å–ø–∏—Å–æ–∫ –≤ GPT
    await bot.send_chat_action(chat_id=first.chat.id, action="typing")
    ai_answer = await gpt_assistant.send_message(
        user_id=user_id,
        thread_id=user.standard_ai_threat_id,
        text=text,
        user_data=user,
        image_bytes=image_buffers,
    )

    images = []
    if type(ai_answer) == dict and ai_answer.get("filename"):
        try:
            await first.reply_document(document=BufferedInputFile(file=ai_answer.get("bytes"),
                                                                    filename=ai_answer.get("filename")))
            ai_answer = "ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"
        except:
            print(traceback.format_exc())
            await first.answer("–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
            return
    elif type(ai_answer) == dict:
        images = ai_answer.get("images")
        ai_answer = ai_answer.get("text")
    # ai_answer = sanitize_with_links(ai_answer)
    from aiogram.enums import ParseMode
    if len(images) == 0:
        for chunk in split_telegram_html(ai_answer):
            await first.reply(
                chunk,

                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True
            )
        return
    else:
        raw = images[0]
        buffer = io.BytesIO(raw)
        buffer.seek(0)

        photo = BufferedInputFile(file=buffer.getvalue(), filename="image.png")
        message = await messages[0].reply_photo(text=ai_answer,
                                            parse_mode=ParseMode.HTML,  # ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                                            disable_web_page_preview=True,
                                            photo=photo)  # —á—Ç–æ–±—ã –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –ª–∏—à–Ω–∏–µ –ø—Ä–µ–≤—å—é
    await ai_requests_repository.add_request(user_id=user.user_id,
                                             has_photo=True,
                                             answer_ai=ai_answer if ai_answer is not None and ai_answer != "" else "–í—ã–¥–∞–ª —Ñ–æ—Ç–æ –∏–ª–∏ –≤–∏–¥–µ–ª",
                                             user_question=first.caption,
                                             photo_id=", ".join(photo_ids),
                                             generate_images=True if len(images) > 0 else False)



@standard_router.message(F.photo)
async def standard_message_photo_handler(message: Message, bot: Bot):
    user_id = message.from_user.id
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    # user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user_id)
    # if user_sub is None:
    #     await message.answer("–ß—Ç–æ–±—ã –æ–±—â–∞—Ç—å—Å—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º GPT —É —Ç–µ–±—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–¥–ø–∏—Å–∫–∞",
    #                          reply_markup=buy_sub_keyboard.as_markup())
    #     return
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    text = message.caption
    photo_bytes_io = io.BytesIO()
    photo_id = message.photo[-1].file_id
    print(photo_id)
    await users_repository.update_last_photo_id_by_user_id(photo_id=photo_id, user_id=user_id)
    # print(photo_id)
    await bot.download(message.photo[-1], destination=photo_bytes_io)
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    # try:
    #     ai_photo = await generate_image_bytes(prompt=message.caption, images=[photo_bytes_io.getvalue()])
    #     await message.answer_photo(BufferedInputFile(file=ai_photo, filename="image.png"))
    # except Exception as e:
    #     await message.answer("–æ—à–∏–±–∫–∞")
    # print()
    ai_answer = await gpt_assistant.send_message(user_id=user.user_id,
                                                 thread_id=user.standard_ai_threat_id,
                                                 text=text,
                                                 user_data=user,
                                                 image_bytes=[photo_bytes_io])
    images = []
    if type(ai_answer) == dict and ai_answer.get("filename"):
        try:
            await message.reply_document(document=BufferedInputFile(file=ai_answer.get("bytes"),
                                                                    filename=ai_answer.get("filename")))
            ai_answer = "ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"
        except:
            print(traceback.format_exc())
            await message.answer("–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
            return
    elif type(ai_answer) == dict:
        images = ai_answer.get("images")
        ai_answer = ai_answer.get("text")
    # ai_answer = sanitize_with_links(ai_answer)
    from aiogram.enums import ParseMode
    if len(images) == 0:
        for chunk in split_telegram_html(ai_answer):
            await message.reply(
                chunk,
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True
            )
    else:
        raw = images[0]
        buffer = io.BytesIO(raw)
        buffer.seek(0)

        photo = BufferedInputFile(file=buffer.getvalue(), filename="image.png")
        message = await message.reply_photo(text=ai_answer,
                                            parse_mode=ParseMode.HTML,  # ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                                            disable_web_page_preview=True,
                                            photo=photo)  # —á—Ç–æ–±—ã –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –ª–∏—à–Ω–∏–µ –ø—Ä–µ–≤—å—é
        await users_repository.update_last_photo_id_by_user_id(photo_id=message.photo[-1].file_id, user_id=user_id)
    await ai_requests_repository.add_request(user_id=user.user_id,
                                             has_photo=True,
                                             photo_id=photo_id,
                                             answer_ai=ai_answer if ai_answer is not None and ai_answer != "" else "–í—ã–¥–∞–ª —Ñ–æ—Ç–æ –∏–ª–∏ —Ñ–∞–π–ª",
                                             user_question=message.caption,
                                             generate_images=True if len(images) > 0 else False)


@standard_router.message(F.voice)
async def standard_message_voice_handler(message: Message, bot: Bot):
    user_id = message.from_user.id
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    # if user is not None and user.full_registration:
    # user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user_id)
    # if user_sub is None:
    #     await message.answer("–ß—Ç–æ–±—ã –æ–±—â–∞—Ç—å—Å—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º GPT —É —Ç–µ–±—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–¥–ø–∏—Å–∫–∞",
    #                          reply_markup=buy_sub_keyboard.as_markup())
    #     return
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    audio_bytes_io = io.BytesIO()
    message_voice_id = message.voice.file_id
    await bot.download(message_voice_id, destination=audio_bytes_io)
    try:
        transcribed_audio_text = await gpt_assistant.transcribe_audio(audio_bytes=audio_bytes_io)
    except:
        await message.answer("–ù–µ –º–æ–≥—É —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å, —á—Ç–æ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
        return
    # print(transcribed_audio_text)
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    ai_answer = await gpt_assistant.send_message(
        user_id=user_id,
        thread_id=user.standard_ai_threat_id,
        text=transcribed_audio_text,
        user_data=user)
    images = []
    if type(ai_answer) == dict and ai_answer.get("filename"):
        try:
            await message.reply_document(document=BufferedInputFile(file=ai_answer.get("bytes"),
                                                                    filename=ai_answer.get("filename")))
            ai_answer = "ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"
        except:
            print(traceback.format_exc())
            await message.answer("–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
            return
    elif type(ai_answer) == dict:
        images = ai_answer.get("images")
        ai_answer = ai_answer.get("text")
    # ai_answer = sanitize_with_links(ai_answer)
    from aiogram.enums import ParseMode
    if len(images) == 0:
        for chunk in split_telegram_html(ai_answer):
            await message.reply(
                chunk,
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True
            )
    else:
        raw = images[0]
        buffer = io.BytesIO(raw)
        buffer.seek(0)

        photo = BufferedInputFile(file=buffer.getvalue(), filename="image.png")
        message = await message.reply_photo(text=ai_answer,
                                            parse_mode=ParseMode.HTML,  # ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                                            disable_web_page_preview=True,
                                            photo=photo)  # —á—Ç–æ–±—ã –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –ª–∏—à–Ω–∏–µ –ø—Ä–µ–≤—å—é
        await users_repository.update_last_photo_id_by_user_id(photo_id=message.photo[-1].file_id, user_id=user_id)
    await ai_requests_repository.add_request(user_id=user.user_id,
                                             has_audio=True,
                                             answer_ai=ai_answer if ai_answer is not None and type(ai_answer) == str and ai_answer != ""  else "–í—ã–¥–∞–ª —Ñ–æ—Ç–æ –∏–ª–∏ —Ñ–∞–π–ª",
                                             user_question=transcribed_audio_text,
                                             generate_images=True if len(images) > 0 else False)


@standard_router.message(
    F.media_group_id,
    F.content_type == "document"
)
@media_group_handler
async def handle_document_album(messages: list[types.Message], bot: Bot):
    first = messages[-1]
    user_id = first.from_user.id
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    await bot.send_chat_action(chat_id=first.chat.id, action="typing")
    text = "\n".join([message.caption or "" for message in messages]) or "–í–æ—Ç –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ –º–Ω–æ–π —Ñ–∞–π–ª—ã, –∏–∑—É—á–∏ –∏—Ö"

    doc_buffers: list[tuple[io.BytesIO, str, str]] = []
    file_ids: list[str] = []

    for msg in messages:
        buf = io.BytesIO()
        await bot.download(msg.document, destination=buf)
        file_name = msg.document.file_name
        print(file_name)
        ext = file_name.split('.')[-1].lower()
        if ext not in OPENAI_ALLOWED_DOC_EXTS:
            await first.reply(
                f"‚ö†Ô∏è –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ ¬´{msg.document.file_name}¬ª –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. "
                f"–ü—Ä–∏—à–ª–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤: {', '.join(sorted(OPENAI_ALLOWED_DOC_EXTS))}"
            )
            return
        doc_buffers.append((buf, file_name, ext))
        file_ids.append(msg.document.file_id)
    if any(message.document.file_name.split('.')[-1].lower() in ['jpg', 'jpeg', 'png', "DNG", "gif", "dng"] for message in messages):
        ai_answer = await gpt_assistant.send_message(
            user_id=user_id,
            thread_id=user.standard_ai_threat_id,
            text=text,
            user_data=user,
            image_bytes=[photo[0] for photo in doc_buffers if photo[2] in ['jpg', 'jpeg', 'png', "DNG", "gif", "dng"]],
            document_bytes=[doc for doc in doc_buffers if doc[2] not in ['jpg', 'jpeg', 'png', "DNG", "gif", "dng"]]
        )
    else:
        ai_answer = await gpt_assistant.send_message(
            user_id=user_id,
            thread_id=user.standard_ai_threat_id,
            text=text,
            user_data=user,
            document_bytes=doc_buffers
        )
    images = []
    if type(ai_answer) == dict and ai_answer.get("filename"):
        try:
            await first.reply_document(caption="ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª", document=BufferedInputFile(file=ai_answer.get("bytes"),
                                                                    filename=ai_answer.get("filename")))
            ai_answer = "ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"
        except:
            print(traceback.format_exc())
            await first.answer("–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
            return
    elif type(ai_answer) == dict:
        images = ai_answer.get("images")
        ai_answer = ai_answer.get("text")
    # print(ai_answer)
    # ai_answer = sanitize_with_links(ai_answer)
    from aiogram.enums import ParseMode
    if len(images) == 0:
        for chunk in split_telegram_html(ai_answer):
            await first.reply(
                chunk,
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True
            )
    else:
        raw = images[0]
        buffer = io.BytesIO(raw)
        buffer.seek(0)

        photo = BufferedInputFile(file=buffer.getvalue(), filename="image.png")
        message = await first.reply_photo(text=ai_answer,
                                            parse_mode=ParseMode.HTML,  # ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                                            disable_web_page_preview=True,
                                            photo=photo)  # —á—Ç–æ–±—ã –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –ª–∏—à–Ω–∏–µ –ø—Ä–µ–≤—å—é
        await users_repository.update_last_photo_id_by_user_id(photo_id=message.photo[-1].file_id, user_id=user_id)
    await ai_requests_repository.add_request(
        user_id=user.user_id,
        has_files=True,
        file_id=", ".join(file_ids),
        answer_ai=ai_answer,
        user_question=text,
        generate_images=True if len(images) > 0 else False
    )



@standard_router.message(F.document, F.media_group_id.is_(None))
async def standard_message_document_handler(message: Message, bot: Bot):
    user_id = message.from_user.id
    user = await users_repository.get_user_by_user_id(user_id=user_id)
    # if user is not None and user.full_registration:
    # user_sub = await subscriptions_repository.get_active_subscription_by_user_id(user_id=user_id)
    # if user_sub is None:
    #     await message.answer("–ß—Ç–æ–±—ã –æ–±—â–∞—Ç—å—Å—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º GPT —É —Ç–µ–±—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–¥–ø–∏—Å–∫–∞",
    #                          reply_markup=buy_sub_keyboard.as_markup())
    #     return
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    # delete_message = await message.reply("–§–æ—Ä–º—É–ª–∏—Ä—É—é –æ—Ç–≤–µ—Ç, —ç—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ –±–æ–ª–µ–µ 5 —Å–µ–∫—É–Ω–¥")
    text = message.caption
    buf = io.BytesIO()
    await bot.download(message.document, destination=buf)
    file_name = message.document.file_name
    # print(file_name)
    ext = file_name.split('.')[-1].lower()
    if ext not in OPENAI_ALLOWED_DOC_EXTS:
        await message.reply(
            f"‚ö†Ô∏è –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ ¬´{message.document.file_name}¬ª –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. "
            f"–ü—Ä–∏—à–ª–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤: {', '.join(sorted(OPENAI_ALLOWED_DOC_EXTS))}"
        )
        return
    if message.document.file_name:
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        extension = message.document.file_name.split('.')[-1].lower()
        if extension in ['jpg', 'jpeg', 'png', "DNG", "gif", "dng"]:
            await users_repository.update_last_photo_id_by_user_id(photo_id=message.document.file_id, user_id=user_id)
            ai_answer = await gpt_assistant.send_message(user_id=user_id,
                                                         thread_id=user.standard_ai_threat_id,
                                                         text=text,
                                                         user_data=user,
                                                         image_bytes=[buf])
        else:
            ai_answer = await gpt_assistant.send_message(user_id=user_id,
                                                         thread_id=user.standard_ai_threat_id,
                                                         text=text,
                                                         user_data=user,
                                                         document_bytes=[(buf, file_name, ext)],
                                                         document_type=extension)
        images = []
        if type(ai_answer) == dict and ai_answer.get("filename"):
            try:
                await message.reply_document(document=BufferedInputFile(file=ai_answer.get("bytes"),
                                                                      filename=ai_answer.get("filename")))
                ai_answer = "ü§ñ–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"
            except:
                print(traceback.format_exc())
                await message.answer("–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")
                return
        elif type(ai_answer) == dict:
            images = ai_answer.get("images")
            ai_answer = ai_answer.get("text")
        # print(ai_answer)
        # ai_answer = sanitize_with_links(ai_answer)
        from aiogram.enums import ParseMode
        if len(images) == 0:
            for chunk in split_telegram_html(ai_answer):
                await message.reply(
                    chunk,
                    parse_mode=ParseMode.HTML,
                    disable_web_page_preview=True
                )
        else:
            # print("sdgsf")
            raw = images[0]
            buffer = io.BytesIO(raw)
            buffer.seek(0)

            photo = BufferedInputFile(file=buffer.getvalue(), filename="image.png")
            message = await message.reply_photo(caption=ai_answer,
                                                parse_mode=ParseMode.HTML,  # ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                                                disable_web_page_preview=True,
                                                photo=photo)  # —á—Ç–æ–±—ã –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –ª–∏—à–Ω–∏–µ –ø—Ä–µ–≤—å—é
            await users_repository.update_last_photo_id_by_user_id(photo_id=message.photo[-1].file_id, user_id=user_id)
        await ai_requests_repository.add_request(user_id=user.user_id,
                                                 answer_ai=ai_answer if ai_answer is not None and ai_answer != "" and type(
                                                     ai_answer) == str else "–í—ã–¥–∞–ª —Ñ–æ—Ç–æ –∏–ª–∏ —Ñ–∞–π–ª",
                                                 user_question=message.caption,
                                                 has_files=True,
                                                 file_id=message.document.file_id
                                                 )


#


